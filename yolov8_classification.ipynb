{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pornchai123/Training/blob/main/yolov8_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh8Cn8gW0EZJ",
        "outputId": "38f0568b-6c7e-4dd5-f74f-542ace66e660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.170 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftYms6DHS9Vk",
        "outputId": "600ca029-f9a4-48fa-afbd-d2f0ff61b1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UQKfBCp0PI2",
        "outputId": "1668f33f-c978-4c18-be2a-16fa990e34ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 78.4MB/s]\n",
            "Ultralytics YOLOv8.0.167 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "\n",
            "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
            "100% 165k/165k [00:00<00:00, 7.52MB/s]\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 169.6ms\n",
            "Speed: 27.1ms preprocess, 169.6ms inference, 461.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnFwSvy20nCL",
        "outputId": "e3a1c5ae-216d-4656-e1f6-56ed9d30acfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.170 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=/content/drive/MyDrive/dataset-classification, epochs=100, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/train... found 1500 images in 5 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/val... found 50 images in 5 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/test... found 150 images in 5 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
            "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
            "  9                  -1  1   1319685  ultralytics.nn.modules.head.Classify         [1024, 5]                     \n",
            "YOLOv8l-cls summary: 183 layers, 36206149 parameters, 36206149 gradients\n",
            "Transferred 300/302 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/train... 1500 images, 0 corrupt: 100% 1500/1500 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/val... 50 images, 0 corrupt: 100% 50/50 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      1/100      1.61G     0.1912         12        224: 100% 94/94 [00:10<00:00,  8.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00,  7.57it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      2/100      1.68G    0.03136         12        224: 100% 94/94 [00:09<00:00,  9.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 27.61it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      3/100      1.68G    0.04194         12        224: 100% 94/94 [00:09<00:00, 10.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 32.00it/s]\n",
            "                   all       0.94          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      4/100      1.68G    0.03188         12        224: 100% 94/94 [00:09<00:00,  9.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 27.89it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      5/100      1.65G    0.04414         12        224: 100% 94/94 [00:09<00:00,  9.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 25.25it/s]\n",
            "                   all       0.98          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      6/100       1.7G    0.02741         12        224: 100% 94/94 [00:08<00:00, 10.66it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 14.66it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      7/100       1.7G    0.03677         12        224: 100% 94/94 [00:09<00:00,  9.62it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 29.83it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      8/100      1.65G    0.02681         12        224: 100% 94/94 [00:09<00:00, 10.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 22.35it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      9/100       1.7G    0.03032         12        224: 100% 94/94 [00:08<00:00, 11.22it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 31.95it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     10/100      1.69G    0.01546         12        224: 100% 94/94 [00:08<00:00, 11.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 30.50it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     11/100       1.7G    0.01422         12        224: 100% 94/94 [00:08<00:00, 10.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 29.04it/s]\n",
            "                   all       0.96          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     12/100       1.7G    0.01341         12        224: 100% 94/94 [00:09<00:00,  9.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 28.45it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     13/100      1.64G    0.01174         12        224: 100% 94/94 [00:09<00:00,  9.51it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 35.16it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     14/100      1.68G   0.008513         12        224: 100% 94/94 [00:09<00:00,  9.59it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 33.09it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     15/100      1.65G   0.006471         12        224: 100% 94/94 [00:09<00:00,  9.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 31.15it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     16/100      1.68G   0.008198         12        224: 100% 94/94 [00:08<00:00, 10.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 25.13it/s]\n",
            "                   all       0.98          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     17/100      1.66G   0.008773         12        224: 100% 94/94 [00:08<00:00, 11.29it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 24.89it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     18/100      1.65G   0.006424         12        224: 100% 94/94 [00:09<00:00,  9.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 25.04it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     19/100      1.64G   0.006751         12        224: 100% 94/94 [00:09<00:00,  9.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 28.36it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     20/100      1.65G   0.004726         12        224: 100% 94/94 [00:09<00:00,  9.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 22.91it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     21/100      1.66G   0.003952         12        224: 100% 94/94 [00:10<00:00,  9.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 33.76it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     22/100       1.7G    0.00587         12        224: 100% 94/94 [00:09<00:00,  9.62it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 29.16it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     23/100      1.67G   0.005833         12        224: 100% 94/94 [00:09<00:00, 10.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 20.65it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     24/100      1.64G    0.01327         12        224: 100% 94/94 [00:08<00:00, 11.50it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 12.83it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     25/100      1.66G   0.008349         12        224: 100% 94/94 [00:08<00:00, 11.60it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 27.31it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     26/100      1.68G    0.01056         12        224: 100% 94/94 [00:08<00:00, 10.55it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 31.97it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     27/100      1.66G   0.006139         12        224: 100% 94/94 [00:09<00:00,  9.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 31.34it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     28/100      1.68G   0.009589         12        224: 100% 94/94 [00:09<00:00,  9.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 24.23it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     29/100      1.66G    0.01025         12        224: 100% 94/94 [00:09<00:00,  9.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 33.77it/s]\n",
            "                   all       0.98          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     30/100      1.68G   0.007806         12        224: 100% 94/94 [00:09<00:00,  9.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 32.58it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     31/100      1.66G   0.005235         12        224: 100% 94/94 [00:10<00:00,  9.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 30.74it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     32/100      1.68G   0.004284         12        224: 100% 94/94 [00:09<00:00,  9.64it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 29.65it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     33/100      1.66G   0.007409         12        224: 100% 94/94 [00:09<00:00,  9.60it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 28.35it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     34/100      1.68G   0.004304         12        224: 100% 94/94 [00:09<00:00,  9.51it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 30.71it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     35/100      1.66G   0.004261         12        224: 100% 94/94 [00:09<00:00,  9.67it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 26.54it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     36/100      1.68G   0.004046         12        224: 100% 94/94 [00:09<00:00,  9.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 20.67it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     37/100      1.66G    0.00273         12        224: 100% 94/94 [00:09<00:00,  9.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 34.78it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     38/100      1.68G   0.005392         12        224: 100% 94/94 [00:09<00:00,  9.43it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 26.41it/s]\n",
            "                   all       0.98          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     39/100      1.66G   0.003695         12        224: 100% 94/94 [00:09<00:00, 10.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 14.60it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     40/100      1.68G   0.001946         12        224: 100% 94/94 [00:08<00:00, 11.60it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 25.38it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     41/100      1.66G   0.002156         12        224: 100% 94/94 [00:08<00:00, 11.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 26.52it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     42/100      1.68G   0.002731         12        224: 100% 94/94 [00:09<00:00, 10.26it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 24.77it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     43/100      1.66G   0.004804         12        224: 100% 94/94 [00:08<00:00, 11.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 32.83it/s]\n",
            "                   all       0.96          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     44/100      1.68G   0.002907         12        224: 100% 94/94 [00:09<00:00,  9.55it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 26.29it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     45/100      1.66G   0.002181         12        224: 100% 94/94 [00:09<00:00,  9.50it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 35.18it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     46/100      1.68G   0.001939         12        224: 100% 94/94 [00:09<00:00,  9.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 30.76it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     47/100      1.66G   0.001896         12        224: 100% 94/94 [00:09<00:00,  9.47it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 19.25it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     48/100      1.68G  0.0009184         12        224: 100% 94/94 [00:09<00:00,  9.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 2/2 [00:00<00:00, 15.48it/s]\n",
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     49/100      1.66G   0.001175         16        224:  66% 62/94 [00:06<00:06,  5.02it/s][ WARN:0@648.947] global loadsave.cpp:248 findDecoder imread_('/content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/train/500/IMG_20230106_001911_jpg.rf.6bafd0582bb021cd463b897b77220464.jpg'): can't open/read file: check file path/integrity\n",
            "     49/100      1.66G   0.001157         16        224:  66% 62/94 [00:06<00:06,  5.02it/s][ WARN:0@649.005] global loadsave.cpp:248 findDecoder imread_('/content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/train/50/IMG_20230106_010009_jpg.rf.1cbe5e5c8f20a4ffcd5751e994bacc42.jpg'): can't open/read file: check file path/integrity\n",
            "     49/100      1.66G   0.001139         16        224:  68% 64/94 [00:06<00:04,  7.30it/s][ WARN:0@649.067] global loadsave.cpp:248 findDecoder imread_('/content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/train/1000/IMG_20230105_235936_jpg.rf.95407f9536b240665c41f55286f80f54.jpg'): can't open/read file: check file path/integrity\n",
            "     49/100      1.66G   0.001122         16        224:  69% 65/94 [00:06<00:03,  9.44it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "[ WARN:0@649.130] global loadsave.cpp:248 findDecoder imread_('/content/drive/.shortcut-targets-by-id/1S49MTHMlykrmMIz1mMm4_kMOkl5SWSbp/dataset-classification/train/500/IMG_20230106_002253_jpg.rf.97dbb40719e203eb0392b9e7567ba9ec.jpg'): can't open/read file: check file path/integrity\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 446, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 341, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 195, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 331, in _do_train\n",
            "    for i, batch in pbar:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1182, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\", line 38, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1345, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "cv2.error: Caught error in DataLoader worker process 1.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 251, in __getitem__\n",
            "    sample = self.album_transforms(image=cv2.cvtColor(im, cv2.COLOR_BGR2RGB))['image']\n",
            "cv2.error: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!yolo train model=yolov8l-cls.pt data=/content/drive/MyDrive/dataset-classification epochs=100 imgsz=224 lr0=0.001\n",
        "#batch=250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nROMguiUO8gd",
        "outputId": "4f543d0e-92c8-49cf-ed26-98e6a0391f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.168 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1441285 parameters, 0 gradients\n",
            "\n",
            "image 1/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003318_jpg.rf.aa7db467bc06d2faa5b98fc543af9bee.jpg: 224x224 20 0.28, 500 0.24, 100 0.21, 1000 0.17, 50 0.10, 3.2ms\n",
            "image 2/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003329_jpg.rf.d493166829c5d2b70d326d2bb2d4d011.jpg: 224x224 100 0.43, 500 0.20, 20 0.16, 1000 0.14, 50 0.07, 3.5ms\n",
            "image 3/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003339_jpg.rf.22974287ea4b88be8d862e93b63cd355.jpg: 224x224 20 0.26, 100 0.23, 500 0.22, 1000 0.20, 50 0.09, 4.1ms\n",
            "image 4/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003350_jpg.rf.849a07cb093afc4ebe212426c1b251e5.jpg: 224x224 100 0.35, 20 0.21, 500 0.18, 1000 0.13, 50 0.13, 3.4ms\n",
            "image 5/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003402_jpg.rf.5d3da328200d2582af07de0de2091c9e.jpg: 224x224 100 0.29, 20 0.24, 500 0.21, 50 0.14, 1000 0.12, 3.6ms\n",
            "image 6/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003415_jpg.rf.d11364e83548d25db157262fa23f8b92.jpg: 224x224 100 0.41, 500 0.18, 20 0.18, 50 0.12, 1000 0.12, 2.9ms\n",
            "image 7/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003426_jpg.rf.3aebbdc5b0ff10e9d94a5c6e5c233e81.jpg: 224x224 100 0.51, 500 0.19, 1000 0.13, 20 0.11, 50 0.06, 3.3ms\n",
            "image 8/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003442_jpg.rf.8ececcb764d364293e7c250eb13e24b4.jpg: 224x224 100 0.31, 20 0.25, 1000 0.16, 500 0.15, 50 0.13, 3.8ms\n",
            "image 9/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003508_jpg.rf.f68d3b4bae4f170649b976e0ef68e986.jpg: 224x224 100 0.35, 20 0.28, 500 0.15, 1000 0.14, 50 0.08, 3.5ms\n",
            "image 10/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003520_jpg.rf.3add6d60eb651375d4c8ac5e0453b378.jpg: 224x224 100 0.35, 1000 0.20, 500 0.18, 20 0.16, 50 0.11, 3.1ms\n",
            "image 11/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003530_jpg.rf.411fb67f6e47a1a503957f5dea7aa6e3.jpg: 224x224 100 0.44, 1000 0.18, 500 0.16, 20 0.15, 50 0.07, 3.2ms\n",
            "image 12/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003541_jpg.rf.07f9b0669b4a587dffa3c87597aef5a9.jpg: 224x224 100 0.27, 20 0.25, 500 0.17, 1000 0.16, 50 0.15, 3.4ms\n",
            "image 13/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003555_jpg.rf.c872c6a8e4f073a03c1a69f57f7a3a01.jpg: 224x224 100 0.37, 500 0.24, 20 0.14, 1000 0.13, 50 0.13, 3.4ms\n",
            "image 14/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003624_jpg.rf.7d7ebbfaa637120a8f7bdb022ced07f8.jpg: 224x224 20 0.24, 100 0.21, 1000 0.21, 500 0.19, 50 0.15, 3.2ms\n",
            "image 15/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003634_jpg.rf.b6a3512b25a163e9139fe15cb115df7c.jpg: 224x224 20 0.26, 50 0.21, 100 0.20, 1000 0.17, 500 0.16, 3.3ms\n",
            "image 16/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003645_jpg.rf.9977afa4b0ad9e62b6d9234091345a8a.jpg: 224x224 100 0.32, 20 0.27, 500 0.17, 1000 0.15, 50 0.09, 3.3ms\n",
            "image 17/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003656_jpg.rf.9cc4ecc997af060e57cac9d642c24096.jpg: 224x224 100 0.30, 20 0.28, 1000 0.18, 500 0.13, 50 0.11, 3.2ms\n",
            "image 18/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003707_jpg.rf.9452e1b02a6da34922b82f1a56d43a5b.jpg: 224x224 20 0.31, 100 0.22, 1000 0.18, 500 0.16, 50 0.13, 3.3ms\n",
            "image 19/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003718_jpg.rf.205897576075bfbe05d6d9b6740b4756.jpg: 224x224 100 0.49, 1000 0.15, 500 0.14, 50 0.11, 20 0.11, 3.2ms\n",
            "image 20/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003729_jpg.rf.91b363b56a88f190637650f0b4c27bba.jpg: 224x224 100 0.44, 1000 0.22, 20 0.13, 50 0.13, 500 0.08, 3.5ms\n",
            "image 21/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003740_jpg.rf.2e67490d4110c82aec4f138b1c24cc8c.jpg: 224x224 100 0.33, 1000 0.24, 20 0.19, 500 0.14, 50 0.11, 3.2ms\n",
            "image 22/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003749_jpg.rf.6df8e2b5a6314841152ec460bf77a0e1.jpg: 224x224 100 0.30, 1000 0.22, 20 0.21, 50 0.17, 500 0.10, 3.4ms\n",
            "image 23/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003758_jpg.rf.3fcc13f1a4dfce1d9f4a1696fa13c749.jpg: 224x224 20 0.28, 500 0.23, 100 0.23, 1000 0.16, 50 0.11, 3.4ms\n",
            "image 24/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003808_jpg.rf.38b5afb7fe45e278ec0cf1bda4f2b080.jpg: 224x224 100 0.36, 500 0.19, 20 0.18, 1000 0.17, 50 0.11, 2.9ms\n",
            "image 25/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003821_jpg.rf.5bca6506a2b6db8daed9f218174a1f65.jpg: 224x224 100 0.33, 20 0.26, 1000 0.16, 500 0.15, 50 0.11, 7.3ms\n",
            "image 26/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003837_jpg.rf.9638b2838f7fa77caefdc9ef62ce3472.jpg: 224x224 100 0.36, 1000 0.22, 500 0.18, 20 0.17, 50 0.08, 3.8ms\n",
            "image 27/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_003847_jpg.rf.d8ebd03ce8fe5d1e6dfd3cd2abc075ac.jpg: 224x224 20 0.31, 100 0.22, 1000 0.19, 500 0.19, 50 0.10, 3.8ms\n",
            "image 28/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_004547_jpg.rf.526fa937f60656a259176b4ce82d4270.jpg: 224x224 100 0.30, 500 0.23, 20 0.21, 50 0.13, 1000 0.13, 3.8ms\n",
            "image 29/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_004607_jpg.rf.8675ba122578eaf07efa71a8eeaf6140.jpg: 224x224 100 0.32, 20 0.26, 500 0.20, 1000 0.12, 50 0.10, 3.8ms\n",
            "image 30/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005229_jpg.rf.0db96be64ec1a7ab2bfeba7f83262318.jpg: 224x224 100 0.27, 20 0.26, 500 0.20, 50 0.13, 1000 0.13, 4.7ms\n",
            "image 31/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005319_jpg.rf.2654cb5b3a24413ce5a927259a02aadf.jpg: 224x224 20 0.28, 100 0.25, 500 0.23, 50 0.12, 1000 0.11, 4.0ms\n",
            "image 32/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005356_jpg.rf.900653d5bc7116276545815ff8d2d038.jpg: 224x224 20 0.36, 500 0.21, 50 0.18, 100 0.14, 1000 0.11, 3.2ms\n",
            "image 33/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005845_jpg.rf.881f727a41cf6369479dea17eae924b0.jpg: 224x224 100 0.26, 20 0.23, 500 0.19, 50 0.16, 1000 0.15, 3.5ms\n",
            "image 34/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005854_jpg.rf.7bb1ed230803c334a9e6c3676586e89f.jpg: 224x224 20 0.32, 100 0.30, 1000 0.14, 500 0.13, 50 0.11, 2.7ms\n",
            "image 35/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005904_jpg.rf.10042ab38dd86842a8c0ce28be745fa8.jpg: 224x224 20 0.30, 100 0.25, 500 0.20, 50 0.12, 1000 0.12, 3.2ms\n",
            "image 36/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005921_jpg.rf.47f25ac67426a246a2bc0a985325d9b3.jpg: 224x224 20 0.33, 100 0.23, 500 0.19, 50 0.12, 1000 0.12, 3.2ms\n",
            "image 37/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005931_jpg.rf.a3d828128fd99daa1de04d4ffc82c2dc.jpg: 224x224 20 0.34, 100 0.28, 500 0.14, 50 0.14, 1000 0.11, 3.2ms\n",
            "image 38/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005939_jpg.rf.da04416efd924894bf8411bb9448d145.jpg: 224x224 100 0.32, 20 0.24, 1000 0.19, 500 0.16, 50 0.10, 3.4ms\n",
            "image 39/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_005948_jpg.rf.4e30a24b6942615fcc86c9f7006b5cc2.jpg: 224x224 100 0.27, 20 0.24, 1000 0.17, 500 0.16, 50 0.15, 3.1ms\n",
            "image 40/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010009_jpg.rf.87f8c90d4c5b1e048c319acc2d15a1bf.jpg: 224x224 20 0.30, 100 0.26, 50 0.15, 500 0.15, 1000 0.14, 2.7ms\n",
            "image 41/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010024_jpg.rf.c12b8d2853a967b264081f76e33246ba.jpg: 224x224 20 0.28, 100 0.28, 50 0.18, 500 0.13, 1000 0.13, 3.2ms\n",
            "image 42/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010033_jpg.rf.b0937981364440bf08d72d26fc8a25e3.jpg: 224x224 20 0.30, 100 0.23, 500 0.19, 50 0.16, 1000 0.11, 3.1ms\n",
            "image 43/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010043_jpg.rf.192d8515b65167ef30c61385b1f4b6fa.jpg: 224x224 20 0.31, 100 0.23, 500 0.20, 50 0.15, 1000 0.11, 3.2ms\n",
            "image 44/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010052_jpg.rf.231abf8ae968bcc2dd38636b1b338f8f.jpg: 224x224 20 0.28, 100 0.25, 50 0.20, 500 0.16, 1000 0.11, 2.8ms\n",
            "image 45/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010101_jpg.rf.8356b7f288c991d05b714b385fc3636d.jpg: 224x224 20 0.38, 100 0.25, 500 0.18, 1000 0.11, 50 0.09, 3.2ms\n",
            "image 46/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010110_jpg.rf.e6dfe85d3265211de46683f768833933.jpg: 224x224 20 0.35, 100 0.24, 500 0.22, 1000 0.13, 50 0.07, 3.2ms\n",
            "image 47/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010119_jpg.rf.43b72dca1bf985dc2d2ad6c013699055.jpg: 224x224 20 0.33, 500 0.23, 100 0.23, 1000 0.11, 50 0.10, 3.3ms\n",
            "image 48/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010128_jpg.rf.6971a1a35a6e7a0c55105f7fb8886fa0.jpg: 224x224 20 0.28, 50 0.22, 100 0.19, 500 0.16, 1000 0.14, 3.0ms\n",
            "image 49/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010136_jpg.rf.7940b659f3d756360d108b33237d4cd1.jpg: 224x224 20 0.41, 100 0.22, 500 0.17, 1000 0.11, 50 0.09, 3.2ms\n",
            "image 50/50 /content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train/IMG_20230106_010204_jpg.rf.562383033dcdf4d7fc5ccbf2404caf08.jpg: 224x224 100 0.29, 20 0.29, 500 0.16, 1000 0.15, 50 0.10, 3.3ms\n",
            "Speed: 1.5ms preprocess, 3.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/classify/predict2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo predict model=/content/runs/classify/train2/weights/best.pt source=/content/drive/MyDrive/dataset-test-object-detection-v8/train/images/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fJaPJ2nQqii",
        "outputId": "3c431b2d-b084-4d7c-ba3e-558c9c7db4e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 406, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 94, in __init__\n",
            "    self._load(model, task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 140, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 610, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 549, in torch_safe_load\n",
            "    return torch.load(file, map_location='cpu'), file  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/runs/classify/train/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!yolo export model=/content/runs/classify/train/weights/best.pt format=tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1fIOoMc7Znh"
      },
      "outputs": [],
      "source": [
        "# https://docs.ultralytics.com/usage/cfg/#train"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}